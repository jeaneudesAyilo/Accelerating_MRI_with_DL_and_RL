{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can RL be used for Classification?\n",
    "*Let's find out...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from baselines.ppo2 import ppo2\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from baselines import deepq\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "import tensorflow as tf\n",
    "\n",
    "from baselines.common.tf_util import make_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_train(batch_size=32, epochs=2):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    score = model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "    print(\"Training Time:\", end_time - start_time)\n",
    "    \n",
    "keras_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RL Interface (gym.Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MnistEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(10)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=(28, 28, 1),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier Using DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mnist_dqn():\n",
    "    logger.configure(dir='./logs/mnist_dqn', format_strs=['stdout', 'tensorboard'])\n",
    "    env = MnistEnv(images_per_episode=1)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = deepq.learn(\n",
    "        env,\n",
    "        \"mlp\",\n",
    "        num_layers=1,\n",
    "        num_hidden=64,\n",
    "        activation=tf.nn.relu,\n",
    "        hiddens=[32],\n",
    "        dueling=True,\n",
    "        lr=1e-4,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.01,\n",
    "        train_freq=4,\n",
    "        learning_starts=10000,\n",
    "        target_network_update_freq=1000,\n",
    "    )\n",
    "\n",
    "    model.save('dqn_mnist.pkl')\n",
    "    env.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = mnist_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, _ = env.step(dqn_model(obs[None])[0])\n",
    "\n",
    "                attempts += 1\n",
    "                if rew > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "mnist_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier using PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_ppo():\n",
    "    logger.configure(dir='./logs/mnist_ppo', format_strs=['stdout', 'tensorboard'])\n",
    "    env = DummyVecEnv([lambda: bench.Monitor(MnistEnv(images_per_episode=1), logger.get_dir())])\n",
    "\n",
    "    model = ppo2.learn(\n",
    "        env=env,\n",
    "        network='mlp',\n",
    "        num_layers=2,\n",
    "        num_hidden=64,\n",
    "        nsteps=32,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        seed=int(time.time()))\n",
    "    \n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "ppo_model = mnist_ppo()\n",
    "print(\"PPO Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_ppo_eval(ppo_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = DummyVecEnv([lambda: MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)])\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), [False]\n",
    "            while not done[0]:\n",
    "                obs, rew, done, _ = env.step(ppo_model.step(obs[None])[0])\n",
    "\n",
    "                attempts += 1\n",
    "                if rew[0] > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "mnist_ppo_eval(ppo_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions?\n",
    "\n",
    "**Facts**\n",
    "- All models used roughly the **same number of parameters**\n",
    "- DQN model splits final layer into two for value and advantages heads\n",
    "- PPO model adds a value head after the final layer\n",
    "- All models are run for equivalent of **2 epochs**\n",
    "\n",
    "**Results**\n",
    "- Standard Supervised Learning\n",
    "    - Training Time: 11.93s\n",
    "    - Test Accuracy: 96.27%\n",
    "    \n",
    "- DQN\n",
    "    - Training Time: 461.5s\n",
    "    - Test Accuracy: 93.48%\n",
    "    \n",
    "- PPO\n",
    "    - Training Time: 638.7s\n",
    "    - Test Accuracy: 95.20%\n",
    "    \n",
    "**Remarks**\n",
    "\n",
    "RL can be used for classification, but it's clearly not the optimal method and doesn't present any advantages over using standard supervised learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
