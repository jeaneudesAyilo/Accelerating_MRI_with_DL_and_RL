{"cells":[{"cell_type":"markdown","metadata":{"id":"9GZf99DuK7rz"},"source":["## Can RL be used for Classification?\n","*Let's find out...*"]},{"cell_type":"markdown","source":["https://www.brthor.com/blog/ai/reinforcement-learning/can-reinforcement-learning-be-used-for-classification/\n","\n","https://unnatsingh.medium.com/deep-q-network-with-pytorch-d1ca6f40bfda"],"metadata":{"id":"-5kUvtIZ5OAW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcs8C1BFK7r5"},"outputs":[],"source":["import time\n","import gym\n","import random\n","import numpy as np\n","from easydict import EasyDict as edict \n","import os   \n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, TensorDataset \n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import torch.optim as optim"]},{"cell_type":"code","source":["#use_cuda=True and torch.cuda.is_available()\n","#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n"],"metadata":{"id":"8cM7H8b26JD7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"gNKZXSMGK7r_"},"source":["### Load MNIST Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cvyYlPAK7sC"},"outputs":[],"source":["mnist_train = torchvision.datasets.MNIST(root='./mnist_experiment', train=True, download=True,) #'./'\n","                             #transform=t)\n","\n","X_mnist_train, y_mnist_train = (mnist_train.data)/255., (mnist_train.targets)\n","X_mnist_train = X_mnist_train.reshape((len(mnist_train),1,28,28))\n","#y_mnist_train_one_hot = torch.nn.functional.one_hot(y_mnist_train).reshape((len(mnist_train),1,-1))\n","\n","mnist_test = torchvision.datasets.MNIST(root= './mnist_experiment',train=False, download=True,)\n","                             #transform=t)\n","\n","X_mnist_test, y_mnist_test = (mnist_test.data)/255., (mnist_test.targets)\n","X_mnist_test =X_mnist_test.reshape((len(mnist_test),1,28,28))\n","#y_mnist_test_one_hot = torch.nn.functional.one_hot(y_mnist_test).reshape((len(mnist_test),1,-1))\n"]},{"cell_type":"code","source":["\n","print(\"X_mnist_train shape : \",X_mnist_train.shape)\n","print(\"y_mnist_train shape : \",y_mnist_train.shape)\n","#print(\"y_mnist_train_one_hot shape : \",y_mnist_train_one_hot.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nzw5Tb6Uncd-","executionInfo":{"status":"ok","timestamp":1667321525682,"user_tz":-60,"elapsed":506,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"db780bd0-ea67-4de6-c380-c5fde7e3e2be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_mnist_train shape :  torch.Size([60000, 1, 28, 28])\n","y_mnist_train shape :  torch.Size([60000])\n"]}]},{"cell_type":"code","source":["class customDataset(Dataset):\n","    ''' \n","        Create a dataloader which takes a tuples of mnist data and \"one\" \n","    '''    \n","\n","    def __init__(self, x_mnist_data, y_mnist_data):\n","        self.x_mnist_data = x_mnist_data\n","        \n","        self.y_mnist_data = y_mnist_data\n","\n","        \n","    def __getitem__(self, index):\n","        sample = {'x': self.x_mnist_data[index], 'y': self.y_mnist_data[index]}\n","        return sample\n","        #return (self.x_mnist_data[index], self.y_mnist_data[index])\n","    \n","    def __len__(self):\n","        return len(self.x_mnist_data)"],"metadata":{"id":"f3_EowQ440r2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","\n","dataset = customDataset(X_mnist_train, y_mnist_train)\n","train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True )\n","\n","dataset_test = customDataset(X_mnist_test , y_mnist_test)\n","test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False )\n"],"metadata":{"id":"aexGVxTt42Um"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mYR4pb9YK7sE"},"source":["### **Baseline classifier**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5tvmtIBK7sH"},"outputs":[],"source":["#https://nextjournal.com/gkoehler/pytorch-mnist\n","\n","nb_classes = 10\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, nb_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","source":[],"metadata":{"id":"loj-iHcxyxPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://visualstudiomagazine.com/articles/2022/02/15/convolutional-neural-networks.aspx\n","\n","def base_classifer_training(max_epochs = 2,ep_log_interval = 5,lrn_rate = 0.005, train_ldr=train_loader):\n","\n","    print(\"\\nCreating CNN network\")\n","\n","    use_cuda=True and torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    net = Net().to(device)   \n","\n","    loss_func = nn.CrossEntropyLoss()  # does log-softmax()\n","    optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n","   \n","    print(\"loss = \" + str(loss_func))\n","    print(\"max_epochs = %3d \" % max_epochs)\n","    print(\"lrn_rate = %0.3f \" % lrn_rate)\n","\n","    print(\"\\nStarting training\")\n","    net.train()  # set mode\n","    for epoch in range(0, max_epochs):\n","      ep_loss = 0  # for one full epoch\n","      #for (batch_idx, batch) in enumerate(train_ldr):\n","      #  (X, y) = batch  # X = pixels, y = target labels\n","      for batch_idx, sample in enumerate(train_ldr):                \n","        X, y = sample['x'], sample['y']\n","        optimizer.zero_grad()\n","        oupt = net(X)\n","        loss_val = loss_func(oupt, y)  # a tensor\n","        ep_loss += loss_val.item()*len(X)  # accumulate\n","        loss_val.backward()  # compute grads\n","        optimizer.step()     # update weights\n","      #if epoch % ep_log_interval == 0:\n","      ep_loss /= len(train_ldr.dataset)\n","      print(\"epoch = %4d   loss = %0.4f\" % \\\n","          (epoch, ep_loss))\n","    print(\"Done \")\n","    \n","    return net\n","\n"],"metadata":{"id":"rm7RZ_YnvxLa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(model, test_ldr = test_loader):\n","  test_loss = 0  \n","  n_correct = 0\n","  #for data in test_ldr:\n","  #  (pixels, labels) = data\n","  for batch_idx, sample in enumerate(test_ldr):                \n","    pixels, labels = sample['x'], sample['y']    \n","    with torch.no_grad():\n","      ouputs = model(pixels)\n","    (_, predicteds) = torch.max(ouputs, 1)\n","    n_correct += (predicteds == labels).sum().item()\n","    loss_func = nn.CrossEntropyLoss(size_average=False) \n","    test_loss += loss_func(ouputs, labels).item()\n","\n","  acc = (n_correct * 1.0) / len(test_ldr.dataset)\n","  test_loss /= len(test_ldr.dataset)\n","\n","  print(\"acc : \",acc)\n","  print(\"test loss : \", test_loss)"],"metadata":{"id":"Z8BvbGaFvxUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["basic_model = base_classifer_training()\n","accuracy(basic_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAtcqw7A8K46","executionInfo":{"status":"ok","timestamp":1667321565250,"user_tz":-60,"elapsed":39110,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"7dc5cf5a-8d2a-4dff-cfd1-dd908e3976fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Creating CNN network\n","loss = CrossEntropyLoss()\n","max_epochs =   2 \n","lrn_rate = 0.005 \n","\n","Starting training\n","epoch =    0   loss = 0.4282\n","epoch =    1   loss = 0.2442\n","Done \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["acc :  0.9284\n","test loss :  0.22807685109972953\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qp2k9H5Q8LZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_train = torchvision.datasets.MNIST(root='./mnist_experiment', train=True, download=True,) #'./'\n","                             #transform=t)\n","\n","X_mnist_train, y_mnist_train = (mnist_train.data)/255., (mnist_train.targets)\n","\n","np.random.seed(25)\n","#reduit = np.random.randint(60000,size=5) \n","reduit = [0,11000,30000]\n","\n","X_reduit, y_reduit = X_mnist_train[reduit], y_mnist_train[reduit]\n","print(\" X_reduit\", X_reduit.shape)\n","print(\" y_reduit\", y_reduit.shape)"],"metadata":{"id":"hpppCA4d8oNo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class c1(Dataset):\n","    ''' \n","        Create a dataloader which takes a tuples of mnist data and \"one\" \n","    '''    \n","\n","    def __init__(self, x_mnist_data, y_mnist_data):\n","        self.x_mnist_data = x_mnist_data\n","        \n","        self.y_mnist_data = y_mnist_data\n","\n","        \n","    def __getitem__(self, index):\n","        sample = {'x': self.x_mnist_data[index], 'y': self.y_mnist_data[index]}\n","        return sample\n","        #return (self.x_mnist_data[index], self.y_mnist_data[index])\n","    \n","    def __len__(self):\n","        return len(self.x_mnist_data)"],"metadata":{"id":"x4ehFaQH8oRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b_size = 1\n","\n","d1 = c1(X_reduit, y_reduit)\n","ldr1 = DataLoader(d1, batch_size=b_size, shuffle=False)\n"],"metadata":{"id":"zVUmMPL48dj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_batch_image(ldr):\n","  for batch_idx, sample in enumerate(ldr):                \n","    image, label = sample['x'], sample['y']\n","    plt.imshow(np.squeeze(image),cmap = \"Greys_r\")\n","    plt.axis(\"off\")\n","    plt.title(f\"label : {label}\")\n","    plt.show()"],"metadata":{"id":"ztHXpFQhCh4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_batch_image(ldr1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":758},"id":"3xp3AeoyCh0D","executionInfo":{"status":"ok","timestamp":1667591706163,"user_tz":-60,"elapsed":606,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"72709d51-a76a-4e7a-cb92-f85603744461"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALoElEQVR4nO3df6zVdR3H8debey9cIEgNZiAga+KATF0Qc8iGIC5Rm/2BbrHGSsoLgw1MxIuQyQiUCImMogljDLeMKUgSjWxkGD8qbKJthDOGMEgmcJmXEOLHuz/Ol3W44/u5l8uF+z7nPh8b24X3+ZzzOXiffA/34+GauwtAPO1aewMALo44gaCIEwiKOIGgiBMIijiBoNp8nGa218xGNfG2bmY3NfNxmr02MjMbaGY7zMyyn7uZ/cfM5jZx/XgzO178+2Nmr5rZ6Cu571LQ5uMsBZfyB0grmCPpx37hgflt7j5Tksysm5ltMbMjZnbMzLaZ2Z3nb+juy939Mw3uc76kH175rcdGnGgWM6s0sx6SRkh6LXHT45IekdRd0rUqhPe6mVXmLXD3v0rqamaDW3DLJYc4i5jZkOxP9mNm9m8z+5mZtW9ws/vMbI+ZHTazBWbWrmj9I2a2y8zqzGyjmd3YAntaJamPCp/Qx81sevbrd5jZ1myvO83srqI1b5rZnOyKVW9mvzezbtms2sxeKrqS/c3Mrs9mPc3sN2Z21Mw+MLPvFt3nM2b2Srb2E0nfknSPpL+7+8m8/bv7SXff7e7nJJmksypEel0jT/1NSfdf6u9XWXH3Nv1D0l5Jo7KPB0m6Q1KlpL6SdkmaWnRbl/RHFT6x+kh6X9J3stmDkj6QNCBbP0vS1gZrb8rZQ62k9U3ZY/bzGyQdkXSfCn/A3pP9vHs2f1PSvyTdLKlj9vPnslmNpNcldZJUkT3nrtlss6SfS6qWdLukjyWNzGbPSDot6evZY3aUtEDSkgZ7vejzlPSupP9m8xcvMr9gnaTvSVrT2p8frfmDK2cRd3/b3be7+xl33yvpl5KGN7jZfHc/6u77JP1E0jeyX58g6Vl33+XuZyTNk3R7U66e7v6cuz9wCVv9pqQN7r7B3c+5+xuSdqgQ63kr3P19d/9U0moVYpMKgX1OhRDOZs/5EzPrLelOSU964Wr3jqRlksYV3ec2d38te8xPJV0jqb4pG3b3WyV1lTRW0p+bsKQ+u/82iziLmNnNZrbezD7KXrrNk9Stwc32F338oaSe2cc3SlqcvVQ8JumoCi/jbrgCW71R0kPnHyt7vGGSehTd5qOij09IOv9Fl1WSNkp62cwOmtmPzKwqex5H3b04tg8b7L/4uUtSnaQuTd10Fv2vJNWa2W2N3LyLpGNNve9yRJwX+oWkf0rq5+5dJT2lQmDFehd93EfSwezj/ZJq3P2aoh8d3X1rC+yr4VuH9kta1eCxOrv7c43ekftpd5/t7gMlDZX0gApXx4OSrjOz4tj6SDqQ2Me7Krx0vlRVkr7QyG0GSNrZjPsuG8R5oS6SPpF03Mz6S5p4kds8YWbXZi8Dp0j6dfbrSyXNMLMvSpKZfdbMHmqhfR3ShZ/ML0n6mpl91cwqsi/y3GVmvRq7IzMbYWZfMrMKFZ7raUnn3H2/pK2Sns3u71ZJ47PHyvOGpC+bWXXi8e4ws2Fm1t7MOprZk5Kul/SXRrY6XNLvGns+5Yw4LzRNhb8T1Ut6Uf8Pr9g6SW9LekfSbyUtlyR3X6vCMcHL2Uvif0hq0kG6mT1lZqlPxGclzcpewk7LQnpQhSv7xypcSZ9Q0/57fl7SKyqEuUvSn1R4qSsV/v7cV4Wr6FpJP3D3P+TdkbsfkrQp20ueDpKWqPAFqwMq/L34fnc/mLfAzL4i6bgXjlTaLMu+MgY0i5kNlLRS0hB3dzM7KemUpJ+6+/ebsP7bkhap8BXige6+x8xelbTc3Tdcyb1HR5xAULysBYIiTiAo4gSCyv2fj6XC23+u1kaAtsrdG56lS+LKCYRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQla29gXI0dOjQ5Pzpp5/OnQ0cODC5tlevXsm5mSXnc+fOTc5nzZqVnOPq4coJBEWcQFDECQRFnEBQxAkERZxAUMQJBGXunj80yx+WsZEjRybnq1atSs67d++enFdWXrnj5VOnTiXnVVVVyXnquW/evLlZe0Kau1/0cJorJxAUcQJBEScQFHECQREnEBRxAkGV7VvGUm+dGjt2bHLt8uXLk/OKiork/PDhw8n52rVrc2fr1q1Lrm3Mvffem5xPmTIlOR80aFDujKOUq4srJxAUcQJBEScQFHECQREnEBRxAkERJxBU2b5lrLa2Nnc2b9685NpDhw4l55MmTUrO16xZk5xfSWPGjEnOV69enZynnnuPHj2atSek8ZYxoMQQJxAUcQJBEScQFHECQREnEBRxAkGV7fs5U98qr7GzvokTJybndXV1zdpTKejUqVNrbwEZrpxAUMQJBEWcQFDECQRFnEBQxAkERZxAUGV7zjl58uTW3kKrGDx48GWt37BhQwvtBJeLKycQFHECQREnEBRxAkERJxAUcQJBEScQVNmec5arfv36JefTp0+/rPs/cODAZa1Hy+HKCQRFnEBQxAkERZxAUMQJBEWcQFBl+y0AS1V1dXVyvmjRouS8pqbmsh4/9flw5syZ5NoZM2Yk588//3yz9lTu+BaAQIkhTiAo4gSCIk4gKOIEgiJOICjiBILinDOYhQsXJuePPfbYZd3/qVOnmj3v2rVrcm1j56CjRo1Kzjdv3pyclyvOOYESQ5xAUMQJBEWcQFDECQRFnEBQxAkExTlnKxg0aFDubOvWrcm19fX1yfmECROS8507dybne/bsyZ0tWLAguXbq1KnJ+Y4dO5LzIUOGJOflinNOoMQQJxAUcQJBEScQFHECQREnEBRxAkFxzhnM/Pnzk/O33norOV+/fn1LbueSnDhxIjmvqqpKzocPH547a+z8t5RxzgmUGOIEgiJOICjiBIIiTiAo4gSCIk4gKM450WJmzpyZnM+ZMyc5X7lyZe5s/PjxybXnzp1LziPjnBMoMcQJBEWcQFDECQRFnEBQxAkExVEKWkzfvn2T8/feey8579y5c+5s2LBhybWl/JYyjlKAEkOcQFDECQRFnEBQxAkERZxAUMQJBFXZ2htA+di7d29y/sILLyTntbW1ubMRI0Yk15byOWcerpxAUMQJBEWcQFDECQRFnEBQxAkERZxAULyfEy1m2rRpyfncuXOT87Nnz+bOevbsmVx77Nix5Dwy3s8JlBjiBIIiTiAo4gSCIk4gKOIEgiJOICjez9kM7dql/0zr1q1bcn769OncWV1dXbP2dDW0b98+OR83blxyXlmZ/nTbtGlT7qyUzzGbiysnEBRxAkERJxAUcQJBEScQFHECQXGU0gw1NTXJ+ZIlS5LzkydP5s769++fXLtv377k/HINGDAgd7Zs2bLk2ltuuSU537JlS3I+evTo5Lyt4coJBEWcQFDECQRFnEBQxAkERZxAUMQJBMU5ZzPs3r07OU+dY0pSdXV17uzuu+9Orl2xYkVy/vjjjyfnkyZNSs579+6dO6uoqEiu3bZtW3L+8MMPJ+e4EFdOICjiBIIiTiAo4gSCIk4gKOIEgiJOICi+BeAVMHny5OR88eLFubPUfw9JOnr0aHLepUuX5Lyxf56yvr4+d7Zw4cLk2qVLlybnR44cSc7bKr4FIFBiiBMIijiBoIgTCIo4gaCIEwiKOIGgOOdsBY8++mjuLHUGKkkdOnRIzrdv356cz549OznfuHFjco6WxzknUGKIEwiKOIGgiBMIijiBoIgTCIo4gaA45wRaGeecQIkhTiAo4gSCIk4gKOIEgiJOICjiBIIiTiAo4gSCIk4gKOIEgiJOICjiBIIiTiAo4gSCIk4gKOIEgiJOICjiBIIiTiAo4gSCIk4gqOQ/jQmg9XDlBIIiTiAo4gSCIk4gKOIEgiJOIKj/AafXxFsI8AwoAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def cycle(iterable,loops = 2):\n","    for i in range(loops):\n","        for x in iterable:\n","            yield x"],"metadata":{"id":"0J7zNwWseJ97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ldr2 = DataLoader(d1, batch_size=b_size, shuffle=True)\n","#plot_batch_image(cycle(ldr1))\n","plot_batch_image(cycle(ldr2,3))"],"metadata":{"id":"BdImlyuag1uD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iterloader = cycle(ldr2,2)\n","examples = enumerate(iterloader)\n"],"metadata":{"id":"KPAYo51znU3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_idx, examples_dico = next(examples)\n","plt.imshow(np.squeeze(examples_dico[\"x\"]))\n","plt.axis(\"off\")\n","plt.title(f\"label : {examples_dico['y']}\")\n","plt.show()"],"metadata":{"id":"B302fAxyndi5","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1667591816827,"user_tz":-60,"elapsed":241,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"d128a901-6cf0-4691-fbcb-6b03f467d5cb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-b6c0e2b236ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples_dico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_dico\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"label : {examples_dico['y']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"code","source":["iterloader = cycle(ldr2,1)\n","examples_dico = next(iterloader)\n","plt.imshow(np.squeeze(examples_dico[\"x\"]))\n","plt.axis(\"off\")\n","plt.title(f\"label : {examples_dico['y']}\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"uKz0zMs3N-5c","executionInfo":{"status":"ok","timestamp":1667592062579,"user_tz":-60,"elapsed":227,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"8b9b9abf-7758-400d-c101-ad5a30e5a8f4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["pour le cycle, si on ne lui applique pas enumerate, next ne s'arrête jamais"],"metadata":{"id":"bSE5Cn-mPHoj"}},{"cell_type":"code","source":[],"metadata":{"id":"c8t7HVKIPGtJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##from : https://github.com/facebookresearch/active-mri-acquisition/blob/main/activemri/envs/envs.py\n","from typing import (\n","    Any,\n","    Callable,\n","    Dict,\n","    Iterator,\n","    List,\n","    Mapping,\n","    Optional,\n","    Sequence,\n","    Sized,\n","    Tuple,\n","    Union,\n",")\n","\n","\n","class CyclicSampler(torch.utils.data.Sampler):\n","    def __init__(\n","        self,\n","        data_source: Sized,\n","        order: Optional[Sized] = None,\n","        loops: int = 1,\n","    ):\n","        torch.utils.data.Sampler.__init__(self, data_source)\n","        assert loops > 0\n","        assert order is None or len(order) == len(data_source)\n","        self.data_source = data_source\n","        self.order = order if order is not None else range(len(self.data_source))\n","        self.loops = loops\n","\n","    def _iterator(self):\n","        for _ in range(self.loops):\n","            for j in self.order:\n","                yield j\n","\n","    def __iter__(self):\n","        return iter(self._iterator())\n","\n","    def __len__(self):\n","        return len(self.data_source) * self.loops     "],"metadata":{"id":"f39US4gjChcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataHandler:\n","    def __init__(\n","        self,\n","        data_source: torch.utils.data.Dataset,\n","        seed: Optional[int],\n","        batch_size: int = 1,\n","        loops: int = 1,\n","        collate_fn: Optional[Callable] = None,\n","    ):\n","        self._iter = None  # type: Iterator[Any]\n","        self._collate_fn = collate_fn\n","        self._batch_size = batch_size\n","        self._loops = loops\n","        self._init_impl(data_source, seed, batch_size, loops, collate_fn)\n","\n","    def _init_impl(\n","        self,\n","        data_source: torch.utils.data.Dataset,\n","        seed: Optional[int],\n","        batch_size: int = 1,\n","        loops: int = 1,\n","        collate_fn: Optional[Callable] = None,\n","    ):\n","        rng = np.random.RandomState(seed)\n","        order = rng.permutation(len(data_source))\n","        sampler = CyclicSampler(data_source, order, loops=loops)\n","        if collate_fn:\n","            self._data_loader = torch.utils.data.DataLoader(\n","                data_source,\n","                batch_size=batch_size,\n","                sampler=sampler,\n","                collate_fn=collate_fn,\n","            )\n","        else:\n","            self._data_loader = torch.utils.data.DataLoader(\n","                data_source, batch_size=batch_size, sampler=sampler\n","            )\n","        self._iter = iter(self._data_loader)\n","\n","    def reset(self):\n","        self._iter = iter(self._data_loader)\n","\n","    def __iter__(self):\n","        return self._iter\n","\n","    def __next__(self):\n","        return next(self._iter)\n","\n","    def seed(self, seed: int):\n","        self._init_impl(\n","            self._data_loader.dataset,\n","            seed,\n","            self._batch_size,\n","            self._loops,\n","            self._collate_fn,\n","        )"],"metadata":{"id":"XB4gpWkQcAVK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_t0SpmUA9-7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pinedaldr =DataHandler(data_source = d1, #ldr = loader\n","        seed= 25,\n","        batch_size = 1,\n","        loops = 1,\n","        collate_fn= None)"],"metadata":{"id":"fwmrUHXYChYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_batch_image(pinedaldr)"],"metadata":{"id":"XYZtn3SrChUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pinedaldr =DataHandler(data_source = d1, #ldr = loader\n","        seed= 25,\n","        batch_size = 1,\n","        loops = 1,\n","        collate_fn= None)\n","\n","examples_pineda = enumerate(pinedaldr)"],"metadata":{"id":"j490X49F-p-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_idx, examples_pineda_dico = next(examples_pineda)\n","plt.imshow(np.squeeze(examples_pineda_dico[\"x\"]))\n","plt.axis(\"off\")\n","plt.title(f\"label : {examples_pineda_dico['y']}\")\n","plt.show()\n","print(examples_pineda_dico[\"x\"].dtype)"],"metadata":{"id":"WdV3eyRA-5cZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##run this cell until getting stopIteration\n","batch_idx, examples_pineda_dico = next(examples_pineda)\n","plt.imshow(np.squeeze(examples_pineda_dico[\"x\"]))\n","plt.axis(\"off\")\n","plt.title(f\"label : {examples_pineda_dico['y']}\")\n","plt.show()\n","print(examples_pineda_dico[\"x\"].dtype)"],"metadata":{"id":"zTl1P7PnQrsp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["sans le enumerate, le DataHandler, s'arrête"],"metadata":{"id":"EuxdweIdRCQz"}},{"cell_type":"markdown","source":["Conculsion : the cycle function that we created is in someway, equivalent to the DataHandler which incoparates a cyclisampler. They objective is the same, be able to loop over the dataset"],"metadata":{"id":"YWbDIDwr5neL"}},{"cell_type":"code","source":["##just to see how permutation work\n","seed = None\n","rng = np.random.RandomState(seed)\n","rng.permutation(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qx6aMIf3KC1L","executionInfo":{"status":"ok","timestamp":1667336637322,"user_tz":-60,"elapsed":363,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"e5d70f87-f5d1-41a8-bb07-0d2124ae6e0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([8, 4, 7, 9, 3, 0, 6, 1, 2, 5])"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["np.random.seed(None)\n","np.random.permutation(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ukEMQ9MKkB8X","executionInfo":{"status":"ok","timestamp":1667866234846,"user_tz":-60,"elapsed":211,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"02c0973b-e342-4a68-e9e0-428f07cd5c58"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([8, 5, 7, 1, 6, 0, 4, 2, 3, 9])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":[],"metadata":{"id":"SjmXy70skfQk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JeyIlIMOK7sJ"},"source":["### Create RL Interface (gym.Env)"]},{"cell_type":"markdown","source":["**Form the data that will be used**"],"metadata":{"id":"oXUFQ9lu4D_8"}},{"cell_type":"code","source":["mnist_train = torchvision.datasets.MNIST(root='./mnist_experiment', train=True, download=True,) #'./'\n","                             #transform=t)\n","\n","X_mnist_train, y_mnist_train = (mnist_train.data)/255., (mnist_train.targets)\n","X_mnist_train = X_mnist_train.reshape((len(mnist_train),1,28,28))\n","#y_mnist_train_one_hot = torch.nn.functional.one_hot(y_mnist_train).reshape((len(mnist_train),1,-1))\n","\n","mnist_test = torchvision.datasets.MNIST(root= './mnist_experiment',train=False, download=True,)\n","                             #transform=t)\n","\n","X_mnist_test, y_mnist_test = (mnist_test.data)/255., (mnist_test.targets)\n","X_mnist_test =X_mnist_test.reshape((len(mnist_test),1,28,28))\n","#y_mnist_test_one_hot = torch.nn.functional.one_hot(y_mnist_test).reshape((len(mnist_test),1,-1))\n"],"metadata":{"id":"5bzPFni92aEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(\"X_mnist_train shape : \",X_mnist_train.shape)\n","print(\"y_mnist_train shape : \",y_mnist_train.shape)\n","#print(\"y_mnist_train_one_hot shape : \",y_mnist_train_one_hot.shape)\n"],"metadata":{"id":"7qTk0Y2c3WCK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1 3  10\n","t = torch.Tensor([1, 2, 3,2,10,5,1,35,5,76,2])\n","a = (t == 2).nonzero(as_tuple=True)[0]\n","\n","#np.random.seed(123)\n","aa = np.random.choice(a, size=1, replace=False)\n","\n","aa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIZkG3W6XZJN","executionInfo":{"status":"ok","timestamp":1668103158297,"user_tz":-60,"elapsed":362,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"49cd9197-d5cf-4355-c548-2ed7c005fd5e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["t[aa]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1h-_pxfDZhWD","executionInfo":{"status":"ok","timestamp":1668103160103,"user_tz":-60,"elapsed":462,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"961bcfb1-00bf-4bd2-905f-5aaca9313239"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2.])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["## We want to reduce the number of training example (and testing example) by taking only a few number of images in each class\n","\n","def reduce_minst_data(x, y ,nb_image_by_class = 50, seed = 123, shuffle=False):\n","\n","  indices = []\n","\n","  for image_label in range(10):\n","    \n","    np.random.seed(seed)\n","    indices_label = np.random.choice((y == image_label).nonzero(as_tuple=True)[0], size=nb_image_by_class, replace=False)\n","    indices.extend(indices_label)\n","  \n","  if shuffle:\n","    np.random.seed(seed)\n","    indices = np.random.permutation(indices) \n","\n","  return x[indices], y[indices]\n"],"metadata":{"id":"q_ws6CYqdicc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_short, y_train_short = reduce_minst_data(X_mnist_train, y_mnist_train ,nb_image_by_class = 50, seed = 123, shuffle=False)\n","\n","X_test_short, y_test_short = reduce_minst_data(X_mnist_test, y_mnist_test , nb_image_by_class = 10, seed = 123, shuffle=False)\n","\n","print(\"X_train_short shape : \",X_train_short.shape)\n","print(\"y_train_short shape : \",y_train_short.shape)\n","print(\"X_test_short shape : \",X_test_short.shape)\n","print(\"y_test_short shape : \",y_test_short.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8Fl7MfEd2xF","executionInfo":{"status":"ok","timestamp":1668103166218,"user_tz":-60,"elapsed":695,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"e412c2e5-8c1f-46b6-8232-7c43a1be080a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_short shape :  torch.Size([500, 1, 28, 28])\n","y_train_short shape :  torch.Size([500])\n","X_test_short shape :  torch.Size([100, 1, 28, 28])\n","y_test_short shape :  torch.Size([100])\n"]}]},{"cell_type":"code","source":["#checking\n","index =399\n","plt.imshow(X_train_short[index].numpy().squeeze())\n","plt.title(f\"label : {y_train_short[index].numpy()}\" )\n","plt.axis(\"off\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"hdE3jftVdx0X","executionInfo":{"status":"ok","timestamp":1668103169529,"user_tz":-60,"elapsed":285,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"f338fe6f-1e2d-43a7-9c9e-607017e1d62c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-0.5, 27.5, 27.5, -0.5)"]},"metadata":{},"execution_count":11},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["class customDataset(Dataset):\n","    ''' \n","        Create a dataloader which takes a tuples of mnist data and \"one\" \n","    '''    \n","\n","    def __init__(self, x_mnist_data, y_mnist_data):\n","        self.x_mnist_data = x_mnist_data\n","        \n","        self.y_mnist_data = y_mnist_data\n","\n","        \n","    def __getitem__(self, index):\n","        sample = {'x': self.x_mnist_data[index], 'y': self.y_mnist_data[index]}\n","        return sample\n","        #return (self.x_mnist_data[index], self.y_mnist_data[index])\n","    \n","    def __len__(self):\n","        return len(self.x_mnist_data)"],"metadata":{"id":"Rr3Fnqad3kIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cycle(iterable,loops = 2):\n","    for i in range(loops):\n","        for x in iterable:\n","            yield x"],"metadata":{"id":"ms4t7HNq7x8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FjYqT1dM5b_k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZwvtOSHK7sJ"},"outputs":[],"source":["\n","class MnistEnv(gym.Env):\n","    def __init__(self, n_loops,  device , images_per_episode=1, data = {\"x\":X_train_short, \"y\":y_train_short} ):\n","        super().__init__()\n","\n","        if device ==\"cpu\": self.device = torch.device(\"cpu\")\n","        else : self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","        print(f\"Running on {device}\")\n","        ##envisager un self.device\n","\n","        self.loader = cycle(iterable = DataLoader(customDataset(data[\"x\"].to(self.device), data[\"y\"].to(self.device)), \n","                                        batch_size = images_per_episode, shuffle=True),\n","                            loops = n_loops)\n","        \n","        self._did_reset = False ##check if we did a reset before pretending to apply step method. otherwise, it could be possible to loop over the data without the reset. it would be possible not to use that variable, and to define the dataloader in the reset method, \n","        ##but that will imply to return the loader in the reset and ensure to pass it to the step method. we prefer follow pineda implementaton : https://github.com/facebookresearch/active-mri-acquisition/blob/main/activemri/envs/envs.py#L214\n","        \n","        self.iterloader = enumerate(self.loader) ## we could have DataHandler instead of that\n","        \n","        self.action_space = gym.spaces.Discrete(10)\n","        self.observation_space = gym.spaces.Box(low=0, high=1,\n","                                                shape=(1, 28, 28),\n","                                                dtype=float)\n","\n","        self.images_per_episode = images_per_episode\n","        self.step_count = 0\n","\n","        print(\"Finish setting environment\")\n","\n","\n","    def step(self, action):\n","\n","        if not self._did_reset:\n","            raise RuntimeError(\n","                \"Attempting to call env.step() before calling env.reset().\"\n","            )\n","\n","        done = False\n","        reward = int(action == self.expected_action)\n","\n","        next_obs = self._next_obs()\n","\n","        self.step_count += 1\n","        if self.step_count >= self.images_per_episode: ## dès qu'on aura fait un step, done sera toujous à true\n","            done = True\n","\n","        return next_obs, reward, done, {}\n","\n","    def reset(self):\n","        self._did_reset = True\n","        self.step_count = 0\n","\n","      \n","        batch_idx, obs = next(self.iterloader) ##first element in the shuffled dataset\n","        self.expected_action = int(obs['y'])\n","\n","        return obs #{'x': self.x_mnist_data[index], 'y': self.y_mnist_data[index]}\n","\n","    def _next_obs(self):\n","\n","        try:\n","           batch_idx, obs = next(self.iterloader)\n","\n","           self.expected_action = int(obs['y'])\n","\n","           return obs\n","\n","        except StopIteration: \n","            return {}\n"]},{"cell_type":"markdown","source":["# The ddqn\n","it is the same model used in the supervised classification, but here it will predict q-values , rather then class"],"metadata":{"id":"Sxq2__07A4Tc"}},{"cell_type":"code","source":[],"metadata":{"id":"BcfevU8hEk90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class QNetwork(nn.Module):\n","    \"\"\" Actor (Policy) Model.\"\"\"\n","    def __init__(self, action_size, seed):\n","        \"\"\"\n","        Initialize parameters and build model.\n","        Params\n","        =======\n","            state_size (int): Dimension of each state\n","            action_size (int): Dimension of each action\n","            seed (int): Random seed\n","        \"\"\"\n","        super(QNetwork,self).__init__() ## calls __init__ method of nn.Module class\n","       # self.seed = torch.manual_seed(seed)\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, action_size) ##nb_classes\n","        \n","    def forward(self,x):\n","        # x = state\n","        \"\"\"\n","        Build a network that maps state -> action values.\n","        \"\"\"\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return x\n"],"metadata":{"id":"5pmBoCtVA2_d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the following [this methodology](https://unnatsingh.medium.com/deep-q-network-with-pytorch-d1ca6f40bfda)"],"metadata":{"id":"AGN2cVuondW7"}},{"cell_type":"code","source":["\n","import numpy as np\n","import random \n","from collections import namedtuple, deque \n","\n","##Importing the model (function approximator for Q-table)\n","#from model import QNetwork\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","#BUFFER_SIZE = int(1e5)  #replay buffer size\n","#BATCH_SIZE = 64         # minibatch size\n","#GAMMA = 0.99            # discount factor\n","#TAU = 1e-3              # for soft update of target parameters\n","#LR = 5e-4               # learning rate\n","#UPDATE_EVERY = 4        # how often to update the network\n","\n","\n","## LinearSchedule https://github.com/openai/baselines/blob/ea25b9e8b234e6ee1bca43083f8f3cf974143998/baselines/common/schedules.py#L76 ; we could have also use : \n","## https://github.com/facebookresearch/active-mri-acquisition/blob/main/activemri/baselines/ddqn.py#L80 ,  in that link (pineda) it is the espsilon decay wchich is used\n","\n","## With the LinearSchedule, the epsilon is expected to decrease linearly. We need to know the total number of steps that will be done. in our example of classificaion with RL, we know that\n","##we went to do 120000 steps (ie loop over the entire training set of 60000 images, 2 times. give the classification of 1 image is one step, the qnet take only one image for a step (in the reconstruction case we will consider a batch),\n","##but will take a batch from the replay buffer.) \n","\n","class LinearSchedule(object):\n","    def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n","        \"\"\"Linear interpolation between initial_p and final_p over\n","        schedule_timesteps. After this many timesteps pass final_p is\n","        returned.\n","        Parameters\n","        ----------\n","        schedule_timesteps: int\n","            Number of timesteps for which to linearly anneal initial_p\n","            to final_p\n","        initial_p: float\n","            initial output value\n","        final_p: float\n","            final output value\n","        \"\"\"\n","        self.schedule_timesteps = schedule_timesteps # by default we will use schedule_timesteps = exploration_fraction * total_timesteps.   exploration_fraction  est la proportion de total_timesteps pendant laquelle l'espsilon va décroitre. par exemple décroitre eps pendant 15000 steps, après le 15000ème step, utiliser final_p\n","        self.final_p = final_p\n","        self.initial_p = initial_p\n","\n","    def value(self, steps_done): \n","        #steps_done nb of steps that are already done\n","        fraction = min(float(steps_done) / self.schedule_timesteps, 1.0)\n","        return self.initial_p + fraction * (self.final_p - self.initial_p)\n","\n","class Agent():\n","    \"\"\"Interacts with and learns form environment.\"\"\"\n","    \n","    def __init__(self,  config):\n","        \"\"\"Initialize an Agent object.\n","        \n","        Params\n","        =======\n","            config (dict): \n","        \"\"\"\n","        self.config = config\n","        self.action_size = config.action_size\n","        self.seed = random.seed(config.seed)\n","\n","        if config.device ==\"cpu\": self.device = torch.device(\"cpu\")\n","        else : self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","        print(f\"Running on {self.device}\")\n","        \n","        \n","        #Q- Network\n","        self.qnetwork_local = QNetwork(self.action_size, self.seed).to(self.device)\n","        self.qnetwork_target = QNetwork(self.action_size, self.seed).to(self.device)\n","        \n","        self.optimizer = optim.Adam(self.qnetwork_local.parameters(),lr=config.lr)\n","\n","        ##espsilon exploration \n","        self.exploration = LinearSchedule(schedule_timesteps=int(self.config.exploration_fraction * self.config.total_timesteps),\n","                              initial_p=self.config.exploration_start_eps,\n","                              final_p=self.config.exploration_final_eps)\n","        \n","        # Replay memory \n","        self.memory = ReplayBuffer(self.action_size, config.buffer_size, config.batch_size, config.seed, config.device)\n","        \n","        \n","        # Initialize time step (for updating every UPDATE_EVERY steps)\n","        self.t_step = 0 # number of timesteps dones, equivalent to step_count.step_count\n","        \n","    def step(self, obs, action, reward, next_step, done): ##here I assume obs = state, and obs is a dico of image and its label\n","        # Save experience in replay memory\n","        self.memory.add(obs, action, reward, next_step, done)\n","\n","        # Learn every UPDATE_EVERY time steps.\n","        self.t_step = (self.t_step+1)% self.config.train_freq\n","        if self.t_step == 0:\n","            # If enough samples are available in memory, get radom subset and learn\n","\n","            if len(self.memory) > self.config.min_length_replay_buffer:\n","                experience = self.memory.sample()\n","                self.learn(experience, self.config.gamma)\n","\n","    def act(self, obs, eps = 0):\n","        \"\"\"Returns action for given state as per current policy\n","        Params\n","        =======\n","            state (array_like): current state\n","            eps (float): epsilon, for epsilon-greedy action selection\n","        \"\"\"\n","        image = obs[\"x\"].float().to(self.device)\n","        self.qnetwork_local.eval()\n","        with torch.no_grad():\n","            action_values = self.qnetwork_local(image)\n","        self.qnetwork_local.train()\n","\n","        #Epsilon -greedy action selction\n","        if random.random() > eps:\n","            return np.argmax(action_values.cpu().data.numpy())\n","        else:\n","            return random.choice(np.arange(self.action_size))\n","            \n","    def learn(self, experiences, gamma):\n","        \"\"\"Update value parameters using given batch of experience tuples.\n","        Params\n","        =======\n","            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples\n","            gamma (float): discount factor\n","        \"\"\"\n","        obs, actions, rewards, next_obs, dones = experiences\n","        ## TODO: compute and minimize the loss\n","        criterion = nn.MSELoss().to(self.device)  ##cette loss est destinée au q_values, et non pas au label des images\n","        self.qnetwork_local.train()\n","        self.qnetwork_target.eval()\n","        #shape of output from the model (batch_size,action_dim) = (batch_size,nb_class)\n","        predicted_targets = self.qnetwork_local(obs[\"x\"]).gather(1,actions)\n","\n","        #################Updates for Double DQN learning###########################\n","        self.qnetwork_local.eval()\n","        with torch.no_grad():\n","            actions_q_local = self.qnetwork_local(next_obs[\"x\"]).detach().max(1)[1].unsqueeze(1).long()\n","            labels_next = self.qnetwork_target(next_obs[\"x\"]).gather(1,actions_q_local) ## attention, ne pas confondre ici ces labels avec les labels des images ; les labels ici sont les q-values labels\n","        self.qnetwork_local.train()\n","        ############################################################################\n","\n","        # .detach() ->  Returns a new Tensor, detached from the current graph.\n","        labels = rewards + (gamma* labels_next*(1-dones)) ### dans le cas de la classification mnist, dones sera tojours un array contenant des 1, comme on considère que la longueur d'épisode est de 1. Et donc normalement, il ne devrait même pas y avoir de next_state (next_obs), puisque le labels_next est multiplié par 0 ; et le gamma risque de ne pas pouvoir jouer son rôle\n","\n","        loss = criterion(predicted_targets,labels).to(self.device)\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        # ------------------- update target network ------------------- #\n","        self.soft_update(self.qnetwork_local,self.qnetwork_target,tau = self.config.tau)\n","            \n","    def soft_update(self, local_model, target_model, tau):\n","        \"\"\"Soft update model parameters.\n","        θ_target = τ*θ_local + (1 - τ)*θ_target\n","        Params\n","        =======\n","            local model (PyTorch model): weights will be copied from\n","            target model (PyTorch model): weights will be copied to\n","            tau (float): interpolation parameter\n","        \"\"\"\n","        for target_param, local_param in zip(target_model.parameters(),\n","                                           local_model.parameters()):\n","            target_param.data.copy_(tau*local_param.data + (1-tau)*target_param.data)\n","\n","\n","class ReplayBuffer:\n","    \"\"\"Fixed -size buffer to store experience tuples.\"\"\"\n","    \n","    def __init__(self, action_size, buffer_size, batch_size, seed, device):\n","        \"\"\"Initialize a ReplayBuffer object.\n","        \n","        Params\n","        ======\n","            action_size (int): dimension of each action\n","            buffer_size (int): maximum size of buffer\n","            batch_size (int): size of each training batch\n","            seed (int): random seed\n","        \"\"\"\n","        \n","        self.action_size = action_size\n","        self.memory = deque(maxlen=buffer_size)\n","        self.batch_size = batch_size\n","        self.experiences = namedtuple(\"Experience\", field_names=[\"obs\",\n","                                                               \"action\",\n","                                                               \"reward\",\n","                                                               \"next_obs\",\n","                                                               \"done\"])\n","        self.seed = random.seed(seed)\n","\n","\n","        if device ==\"cpu\": self.device = torch.device(\"cpu\")\n","        else : self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","        print(f\"Running on {self.device}\")\n","        \n","    def add(self,obs, action, reward, next_obs,done):\n","        \"\"\"Add a new experience to memory.\"\"\"\n","        e = self.experiences(obs,action,reward,next_obs,done)\n","        self.memory.append(e)\n","        \n","    def sample(self):\n","        \"\"\"Randomly sample a batch of experiences from memory\"\"\"\n","\n","        experiences = random.sample(self.memory,k=self.batch_size)\n","        \n","        #obs = {\"x\" : torch.from_numpy(np.vstack([e.obs[\"x\"] for e in experiences if e is not None])).float().to(self.device) ,  # en réalité on avait pas besoin de train le label, puisqu'on l'utilise seulement dans l'attribution de la récompense, après ça c'est fini,ce n'est plus utiliser\n","        #      \"y\" :torch.from_numpy(np.vstack([e.obs[\"y\"] for e in experiences if e is not None])).float().to(self.device) }\n","\n","        obs = {\"x\" : torch.from_numpy(np.vstack([e.obs[\"x\"] for e in experiences if e is not None])).float().to(self.device) } \n","\n","\n","        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(self.device)\n","\n","        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(self.device)\n","\n","        #next_obs = {\"x\" :torch.from_numpy(np.vstack([e.next_obs[\"x\"] for e in experiences if e is not None])).float().to(self.device),\n","        #              \"y\" :torch.from_numpy(np.vstack([e.next_obs[\"y\"] for e in experiences if e is not None])).float().to(self.device)}\n","\n","        next_obs = {\"x\" :torch.from_numpy(np.vstack([e.next_obs[\"x\"] for e in experiences if e is not None])).float().to(self.device)} ## dans quel cas on aurait None ??\n","\n","        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n","        \n","        return (obs,actions,rewards,next_obs,dones) #next_obs is nothing else than a new image and its corresponding label, et si jamais on a besoin de son y ??\n","\n","    def __len__(self):\n","        \"\"\"Return the current size of internal memory.\"\"\"\n","        return len(self.memory)\n"],"metadata":{"id":"ECZdWFFfGkRK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train the Agent with DQN"],"metadata":{"id":"D7bSaihw0poL"}},{"cell_type":"code","source":["\n","def train_dqn(config):\n","    \"\"\"Deep Q-Learning\n","       \n","    \"\"\"\n","\n","    config = edict(config)\n","    \n","    agent = Agent(config)\n","    env = MnistEnv(n_loops=config.num_loops_train_data, device=config.device, images_per_episode=1, data = {\"x\":X_train_short, \"y\":y_train_short}) \n","\n","\n","    scores = [] # list containing score from each episode\n","    scores_window = deque(maxlen=100) # last 100 scores\n","\n","    #eps = eps_start\n","\n","    obs = env.reset()\n","\n","    epoch = 0\n","    while obs != {}: ##if next_obs== {}, then we are at the end of our dataset\n","        \n","          action = agent.act(obs , agent.exploration.value(env.step_count) )\n","          next_obs, reward, done, _ = env.step(action)\n","          agent.step(obs,action,reward,next_obs,done)\n","          ## above step decides whether we will train(learn) the network\n","          ## actor (local_qnetwork) or we will fill the replay buffer\n","          ## if len replay buffer is equal to the min_length_replay_buffer then we will\n","          ## train the network or otherwise we will add experience tuple in our \n","          ## replay buffer.\n","          obs = next_obs\n","\n","          if env.step_count%20==0: print(f\"we are at step {env.step_count}\")\n","\n","          if reward > 0: correct = 1 ##we know that if rewoard =1, the label is ocrrectly predicted , if 0, it is wrong\n","          else: correct =0 \n","          \n","          scores.append(correct) \n","\n","          if len(scores)==len(X_train_short): ##we have done one tour of the training dataset\n","\n","                print(f\"accuracy on training epoch {epoch} is {round(correct/len(X_train_short))}\") ## len(X_train_short) should be = total_timesteps\n","\n","                epoch += 1\n","\n","                scores = []\n","\n","    torch.save(agent.qnetwork_local.state_dict(),os.path.join(config.saving_path,'checkpoint.pth') ) \n","      \n","    #return agent.qnetwork_local\n","\n"],"metadata":{"id":"voV7AMJ20DZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["configuration = {\n","    \"images_per_episode\":1, ## equivalent to number of parallel episodes in pineda\n","    \"nb_columns_to_acquire\":5, ###for reconstrution\n","    \"nb_columns_preselected\":2,\n","    \"num_loops_train_data\" : 2, #equivalent to number of epoch in supervised learning\n","    \"action_size\" : 10, ##mnist number of classes\n","    \"seed\" : 25,\n","    \"buffer_size\" :100, #10000,\n","    \"batch_size\":32, ##batch size in the replay buffer, note that one could specify another batch_size when passing image to dqn\n","    \"gamma\":1.0, ## discount factor, dans ce cas de classification mnist, il n'y a pas de récompense à long terme, donc l'action courant est très valorisée\n","    \"tau\":1e-3, # for soft update of target parameters\n","    \"lr\":1e-4,\n","    \"target_network_update_freq\":1000, ##update the target network every `target_network_update_freq` steps\n","    \"learning_starts\": 32, #10000,\n","    \"train_freq\":4, ##update the model every `train_freq` steps\n","    \"exploration_fraction\":0.1,\n","    \"exploration_final_eps\":0.01,\n","    \"total_timesteps\": 1000, #int(1.2e5), 100 =500*2 # number of , pour rendre automatque on aurait pu le calculer dans l'environnement, avec num_loops_train_data*len(self.train_data_loader.dataset)\n","    \"exploration_start_eps\":1.0,\n","    \"min_length_replay_buffer\": 32, #100, #taille minimum du replay buffer à atteindre avant de commencer l'apprentissage ie la mise du qnetwork\n","    \"device\": \"cpu\",\n","    \"saving_path\":\"./\"\n","    }\n","\n","##we could have also set a frequency of checkpoint saving, and the frequency of evaluating the ddqn on validation/test set. And specify, where to save the checkpoint, and whether or not\n","##we should save the checkpoint if result on valiation are good or bad relatively to the previous checkpoint."],"metadata":{"id":"XNgjMRE1iMbj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dqn(configuration)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ka5ynvQCoVUK","executionInfo":{"status":"ok","timestamp":1668105495233,"user_tz":-60,"elapsed":5870,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"7693b3e7-d387-40ce-9c0a-043432db8fc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on cpu\n","Running on cpu\n","Running on cpu\n","Finish setting environment\n","we are at step 20\n","we are at step 40\n","we are at step 60\n","we are at step 80\n","we are at step 100\n","we are at step 120\n","we are at step 140\n","we are at step 160\n","we are at step 180\n","we are at step 200\n","we are at step 220\n","we are at step 240\n","we are at step 260\n","we are at step 280\n","we are at step 300\n","we are at step 320\n","we are at step 340\n","we are at step 360\n","we are at step 380\n","we are at step 400\n","we are at step 420\n","we are at step 440\n","we are at step 460\n","we are at step 480\n","we are at step 500\n","accuracy on training epoch 0 is 0\n","we are at step 520\n","we are at step 540\n","we are at step 560\n","we are at step 580\n","we are at step 600\n","we are at step 620\n","we are at step 640\n","we are at step 660\n","we are at step 680\n","we are at step 700\n","we are at step 720\n","we are at step 740\n","we are at step 760\n","we are at step 780\n","we are at step 800\n","we are at step 820\n","we are at step 840\n","we are at step 860\n","we are at step 880\n","we are at step 900\n","we are at step 920\n","we are at step 940\n","we are at step 960\n","we are at step 980\n","we are at step 1000\n","accuracy on training epoch 1 is 0\n"]}]},{"cell_type":"markdown","source":["## Evaluate the agent"],"metadata":{"id":"Fb1weeDuiRpq"}},{"cell_type":"code","source":["#load the weights from file\n","\n","def mnist_dqn_eval(config):\n","    \n","    config = edict(config)\n","\n","    env = MnistEnv(n_loops=1, device= config.device, images_per_episode=1, data = {\"x\": X_test_short,\"y\": y_test_short}) \n","    agent = Agent(config)\n","    agent.qnetwork_local.load_state_dict(torch.load(os.path.join(config.saving_path,'checkpoint.pth')))\n","\n","    attempts, correct = 0, 0\n","\n","    obs = env.reset()\n","\n","    while obs != {}:\n","      attempts += 1\n","      #img = plt.imshow(env.render(mode='rgb_array'))        \n","      action = agent.act(obs)\n","      next_obs,reward,done,_ = env.step(action) ##_ is related to info\n","      obs = next_obs\n","     \n","      if reward > 0: correct += 1\n","\n","    print('Accuracy: {0}%'.format((float(correct)/attempts) * 100))\n","\n","    env.close()\n","\n","##10 Novembre 2022, 18h37    \n","\n"],"metadata":{"id":"c1sFt2daTcGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_dqn_eval(configuration)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoGS1qMLoLHk","executionInfo":{"status":"ok","timestamp":1668105690321,"user_tz":-60,"elapsed":261,"user":{"displayName":"Ayayi AYILO","userId":"01654688474303829088"}},"outputId":"aff5cb81-d88d-4469-e74f-b0485b5c490d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on cpu\n","Finish setting environment\n","Running on cpu\n","Running on cpu\n","Accuracy: 11.0%\n"]}]},{"cell_type":"markdown","metadata":{"id":"ce3lP8esK7sU"},"source":["### Conclusions?\n","\n","**Remarks**\n","\n","RL can be used for classification, but it's not the optimal method and doesn't present any advantages over using standard supervised learning. This is purely experimental work (and there might be some mistakes in code)  to launch coding of reconstruction with ddqn"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}